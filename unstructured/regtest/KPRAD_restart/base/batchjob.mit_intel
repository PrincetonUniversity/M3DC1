#!/bin/bash
#SBATCH -J KPRAD_restart
#SBATCH -n 48
##SBATCH --gres=gpu:4
#SBATCH --time=00:30:00
#SBATCH -p sched_mit_psfc_r8
#SBATCH --mem-per-cpu=7500M
#SBATCH -o C1stdout

touch started

PARTS=48
cp -p ../mesh/part* .
#$M3DC1_MPIRUN -n $PARTS /orcd/nese/psfc/001/software/scorec/gcc12.2.0-openmpi4.1.4/petsc3.19.2/bin/split_smb analytic-2K.smb part.smb $PARTS
echo $? > mesh_partitioned

export SLURM_CPU_BIND="cores"
echo $SLURM_CPUS_ON_NODE

# Run M3D-C1
cp C1input.1 C1input
mpirun -n $SLURM_NTASKS m3dc1_2d -pc_factor_mat_solver_type mumps

# Run M3D-C1
cp C1input.2 C1input
mpirun -n $SLURM_NTASKS m3dc1_2d -pc_factor_mat_solver_type mumps

#sbatch -x node[2100-2104,2119,2300-2304,2319]

touch finished

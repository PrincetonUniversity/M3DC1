Updated

1. login from pppl portal
	ssh portal

2. code

3. load modules and set enviroments
        module load intel/2018.u1 openmpi/3.0.0 gcc/6.1.0
        module load gsl fftw/3.3.7 szip/2.1.1 hdf5-parallel/1.10.2
        setenv PSPLINE_DIR /p/swim/jchen/PSPLINE/LINUX/portalr6

    and

    copy sunfire.openmpi-3.0.0.mk sunfire.pppl.gov.mk

4. compile code
  For PETSc-real
    - (2D) make OPT=1
    - (3D) make 3D=1 OPT=1 MAX_PTS=60

  For PETSc-complex, 
    - make OPT=1 COM=1
    - add PAR=1 for PIC 

5. mesh utility
  See $(SCOREC_UTIL_DIR) in .mk file

6. prepare jobscript

	#!/bin/bash -vx
        #SBATCH --partition=kruskal;mque;ellis;greene etc.
        #SBATCH --ntasks=N (max=64)
        #SBATCH -J m3dc1
	#SBATCH -t 01:00:00
        #SBATCH --mail-type=END
        #SBATCH --mail-user=<username>@pppl.gov

	#2D complex
	mpirun --bind-to none -np N ./m3dc1_2d_complex -pc_factor_mat_solver_package mumps

	#2D real
	mpirun --bind-to none -np N ./m3dc1_2d

	#3D real with PETSc
	mpirun --bind-to none  -np N ./m3dc1_3d -ipetsc -options_file options_bjacobi

   **** 6.1 options_bjacobi ***
	-pc_type bjacobi
	-pc_bjacobi_blocks 16
	-sub_pc_type lu
	-sub_pc_factor_mat_solver_package superlu_dist
	-sub_ksp_type preonly
	-ksp_type fgmres
	-ksp_gmres_restart 220
	-ksp_max_it 10000
	-ksp_rtol 1.e-9
	-ksp_atol 1.e-20
	-ksp_converged_reason
	-on_error_abort


7. submit job
        sbatch jobscript
	
	or:   sbatch --dependency=afterok:123 jobscript

8. list all curent jobs for a user
        squeue -u <username>

9. delete a job
        scancel <jobid>

NOTE:  To enable subsequent jobs to run on separate processes, use:
       mpiexec --bind-to none -np 16 .....
       DO NOT include #SBATCH --exclusive


1. login from pppl portal
	ssh portal

2. code

3. load modules and set enviroments
        module load intel/2015.u1
        module load openmpi/1.8.4
	module load lapack/3.6.1
	module load gsl/1.16
	module load szip/2.1
	module load hdf5-parallel
	module load hdf/4.2r1
	module load zlib
        module load scalapack
        module load fftw
        setenv PSPLINE_DIR /p/swim/jchen/PSPLINE/LINUX/portalr6

  For PETSc-real
        setenv PETSC_DIR /p/swim/jchen/PETSC/petsc-3.5.3
        setenv PETSC_ARCH portalr6-intel-openmpi-1.8.4

  For PETSc-complex
        setenv PETSC_DIR /p/swim/jchen/PETSC/petsc-3.5.3
        setenv PETSC_ARCH portalr6-intel-openmpi-1.8.4-complex
 
4. compile code 
  	2D real: make OPT=1 
	2D complex: make OPT=1 COM=1 
            - add PAR=1 to run PIC
	3D real: make 3D=1 OPT=1 MAX_PTS=60 

5. mesh utility
	/p/tsc/m3dc1/lib/SCORECLib/rhel6/utilities/

6. prepare jobscript

	#!/bin/bash -vx
        #SBATCH --partition=kruskal
        #SBATCH --ntasks=N (max=64)
        #SBATCH -J m3dc1
	#SBATCH -t 01:00:00
        #SBATCH --mail-type=END
        #SBATCH --mail-user=<username>@pppl.gov

	#2D complex
	mpirun --bind-to none -np N ./m3dc1_2d_complex -pc_factor_mat_solver_package mumps

	#2D real
	mpirun --bind-to none -np N ./m3dc1_2d

	#3D real
	mpirun --bind-to none  -np N  ./m3dc1_3d -ipetsc -options_file options_bjacobi

7. submit job
        sbatch jobscript
	
	or:   sbatch --dependency=afterok:123 jobscript

8. list all curent jobs for a user
        squeue -u <username>

9. delete a job
        scancel <jobid>

NOTE:  To enable subsequent jobs to run on separate processes, use:
       mpirun --bind-to none -np 16 .....
       DO NOT include #SBATCH --exclusive

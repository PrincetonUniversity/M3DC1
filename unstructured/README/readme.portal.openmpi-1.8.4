1. login from pppl portal
	ssh portal

2. code

3. load modules and set enviroments
        module load intel/2015.u1
        module load openmpi/1.8.4
	module load gsl/1.16
	module load szip/2.1
	module load hdf5-parallel
	module load hdf/4.2r1
	module load zlib
        module load scalapack
        module load fftw
        setenv PSPLINE_DIR /p/swim/jchen/PSPLINE/LINUX/portalr6

4. compile code 
  For PETSc-real
    - (2D) make OPT=1
    - (3D) make 3D=1 OPT=1 MAX_PTS=60

  For PETSc-complex,
    - make OPT=1 COM=1
    - add PAR=1 for PIC

5. mesh utility
	/p/tsc/m3dc1/lib/SCORECLib/rhel6/openmpi-1.8.4/utilities/

6. prepare jobscript

	#!/bin/bash -vx
        #SBATCH --partition=kruskal;mque;ellis etc.
        #SBATCH --ntasks=N (max=64)
        #SBATCH -J m3dc1
	#SBATCH -t 01:00:00
        #SBATCH --mail-type=END
        #SBATCH --mail-user=<username>@pppl.gov

	#2D complex
	mpirun --bind-to none -np N ./m3dc1_2d_complex -pc_factor_mat_solver_package mumps

	#2D real
	mpirun --bind-to none -np N ./m3dc1_2d

	#3D real
	mpirun --bind-to none  -np N  ./m3dc1_3d -ipetsc -options_file options_bjacobi

7. submit job
        sbatch jobscript
	
	or:   sbatch --dependency=afterok:123 jobscript

8. list all curent jobs for a user
        squeue -u <username>

9. delete a job
        scancel <jobid>

NOTE:  To enable subsequent jobs to run on separate processes, use:
       mpirun --bind-to none -np 16 .....
       DO NOT include #SBATCH --exclusive

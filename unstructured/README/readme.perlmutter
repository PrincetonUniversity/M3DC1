Mon Jul  8 09:39:44 PDT 2019

1. login from cori 
   ssh -P cori.nersc.gov -l [username]
   ssh perlmutter

   direct login
   ssh -P perlmutter-p1.nersc.gov -l [username]
   or
   ssh -P saul-p1.nersc.gov -l [username]

2. code
   git clone git@github.com:PrincetonUniversity/M3DC1.git 
   git clone -b [branch] git@github.com:PrincetonUniversity/M3DC1.git 
   git commit -m "perlmutter code porting"
   git push origin master

3. load modules and set environment
   module load cmake python/3.9-anaconda-2021.11

4. compile code
   perlmutter.mk

   make OPT=1 RL=1 MAX_PTS=25 ARCH=perlmutter
   make OPT=1 COM=1 MAX_PTS=25 ARCH=perlmutter
   make 3D=1 OPT=1 MAX_PTS=60 ARCH=perlmutter
   make 3D=1 OPT=1 MAX_PTS=60 ARCH=perlmutter ST=1
   (These modules crashes at restart: cray-hdf5-parallel/1.12.0.7 cray-netcdf-hdf5parallel/4.7.4.7
    So rebuilt hdf5, netcdf-c, netcdf-fortran on 2/15/2022.)


5. mesh utility

6. run jobscript:

   6.1 options_bjacobi *****

        -pc_type bjacobi
        -pc_bjacobi_blocks 4
        -sub_pc_type lu
        -sub_pc_factor_mat_solver_type mumps
        -sub_ksp_type preonly
        -ksp_type fgmres
        -ksp_gmres_restart 220
        -ksp_rtol 1.e-9
        -ksp_atol 1.e-20
        -ksp_converged_reason

        -hard_pc_type bjacobi
        -hard_pc_bjacobi_blocks 4
        -hard_sub_pc_type lu
        -hard_sub_pc_factor_mat_solver_type mumps
        -hard_sub_ksp_type preonly
        -hard_ksp_type fgmres
        -hard_ksp_gmres_restart 220
        -hard_ksp_rtol 1.e-9
        -hard_ksp_atol 1.e-20
        -hard_ksp_converged_reason

        -on_error_abort

   Please change the number of blocks (here 4) to match the number of plane in your 'C1input' file.

   We have another set of options with 'hard_" as the prefix for PETSC VERSION 3.8 or newer
   to isolate the hard solves (#5, #17) from easier ones for optimization purpose.

7. submit job: sample slurm script "batchjob.cori_gpu_pgi"
   #!/bin/bash
   #SBATCH -A m3984_g
   #SBATCH -p debug
   #SBATCH -C gpu
   #SBATCH -n 48
   #SBATCH -J m3dc1_regtest_adapt
   #SBATCH -t 0:30:00
   #SBATCH -o C1stdout

   export SLURM_CPU_BIND="cores"

   srun -n 32 m3dc1_2d_complex -pc_factor_mat_solver_type mumps
   srun -n 32 m3dc1_2d -pc_factor_mat_solver_type mumps
   srun -n 32 m3dc1_3d -options_file options_bjacobi.type_mumps

8. regression tests
   cd unstructured
   export M3DC1_MPIRUN=srun M3DC1_VERSION=local M3DC1_ARCH=perlmutter
   make bin ARCH=$M3DC1_ARCH
   cd _perlmutter/bin/; export PATH=`pwd`:$PATH
   cd ../../regtest/
   ./run $M3DC1_ARCH
   ./check $M3DC1_ARCH



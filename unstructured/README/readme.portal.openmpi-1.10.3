Updated

1. login from pppl portal
	ssh portal

2. code

3. load modules and set enviroments
  	module load intel/2015.u1 openmpi/1.10.3
        module load gsl szip hdf5-parallel/1.8.17
        setenv PSPLINE_DIR /p/swim/jchen/PSPLINE/LINUX/portalr6

    and

    copy sunfire.openmpi-1.10.3.mk sunfire.pppl.gov.mk

4. compile code
  For PETSc-real
    - (2D) make OPT=1
    - (3D) make 3D=1 OPT=1 MAX_PTS=60

  For PETSc-complex, 
    - make OPT=1 COM=1
    - add PAR=1 for PIC 

  Set SCORECVER in order to link with various m3dc1_scorec versions
  (ex) if SCORECVER=debug it will link to a debug version of SCOREC libraries 
       (lots of print statements & sanity check)

5. mesh utility
    /p/tsc/m3dc1/lib/SCORECLib/rhel6/intel2015-openmpi1.10.3-gcc4.4.7/bin

6. prepare jobscript

	#!/bin/bash -vx
        #SBATCH --partition=kruskal;mque;ellis etc.
        #SBATCH --ntasks=N (max=64)
        #SBATCH -J m3dc1
	#SBATCH -t 01:00:00
        #SBATCH --mail-type=END
        #SBATCH --mail-user=<username>@pppl.gov

	#2D complex
	mpirun --bind-to none -np N ./m3dc1_2d_complex -pc_factor_mat_solver_package mumps

	#2D real
	mpirun --bind-to none -np N ./m3dc1_2d

	#3D real with PETSc
	mpirun --bind-to none  -np N ./m3dc1_3d -ipetsc -options_file options_bjacobi

       #3D real with Trilinos
       mpirun --bind-to none  -np N ./m3dc1_3d_trilinos
 
7. submit job
        sbatch jobscript
	
	or:   sbatch --dependency=afterok:123 jobscript

8. list all curent jobs for a user
        squeue -u <username>

9. delete a job
        scancel <jobid>

NOTE:  To enable subsequent jobs to run on separate processes, use:
       mpiexec --bind-to none -np 16 .....
       DO NOT include #SBATCH --exclusive

